{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from imutils import contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import glob\n",
    "# import os\n",
    "\n",
    "# # new folder path (may need to alter for Windows OS)\n",
    "# # change path to your path\n",
    "# path = '/Users/tareklein/Downloads/archive/train/plus cleaned' #the path where to save resized images\n",
    "# # create new folder\n",
    "# if not os.path.exists(path):\n",
    "#     os.makedirs(path)\n",
    "\n",
    "# # loop over existing images and resize\n",
    "# # change path to your path\n",
    "# for filename in glob.glob(path + '/*.jpg'): #path of raw images\n",
    "#     img = Image.open(filename).resize((28,28))\n",
    "#     # save resized images to new folder with existing filename\n",
    "#     img.save('{}{}{}'.format(path,'/',os.path.split(filename)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "    return (tf.cast(image, tf.float32) / 255.0, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mnist_corrupted = 'mnist_corrupted'\n",
    "mnist = 'mnist'\n",
    "\n",
    "dataset = mnist_corrupted\n",
    "\n",
    "(train_dataset, test_dataset), ds_info = tfds.load(\n",
    "    dataset,\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    "    )\n",
    "\n",
    "# (train_dataset2, test_dataset2), ds_info = tfds.load(\n",
    "#     mnist_corrupted,\n",
    "#     split=['train', 'test'],\n",
    "#     shuffle_files=True,\n",
    "#     as_supervised=True,\n",
    "#     with_info=True\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# Store dataset in cache\n",
    "train_dataset = train_dataset.cache()\n",
    "# Shuffle data\n",
    "train_dataset = train_dataset.shuffle(len(train_dataset))\n",
    "# Split up into a batch of 64\n",
    "train_dataset = train_dataset.batch(64)\n",
    "# Grab other stuff before it done dealing with current stuff\n",
    "# Optimization \n",
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "test_dataset = test_dataset.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# Split up into a batch of 64\n",
    "test_dataset = test_dataset.batch(64)\n",
    "# Store dataset in cache\n",
    "test_dataset = test_dataset.cache()\n",
    "# Grab other stuff before it done dealing with current stuff\n",
    "# Optimization \n",
    "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise image tensor (batch has to be 1)\n",
    "visualise = False\n",
    "if visualise:\n",
    "    from tensorflow.keras.datasets import mnist\n",
    "    x = 0\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    train_dataset = train_dataset.shuffle(len(train_dataset))\n",
    "    \n",
    "    for (img, label) in train_dataset:\n",
    "        if label.numpy() == x:\n",
    "            print(img.numpy(), label.numpy())\n",
    "            x+=1\n",
    "        if x == 10:\n",
    "            break\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = False\n",
    "if train:\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.Input((28,28,1)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train_dataset, epochs=30, validation_data=(train_dataset))\n",
    "\n",
    "\n",
    "    model.save('handwritten.model')\n",
    "else:\n",
    "    pass\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('handwritten.model')\n",
    "\n",
    "loss, accuracy = model.evaluate(train_dataset)\n",
    "\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = False\n",
    "if plot:\n",
    "    from matplotlib.lines import lineStyles\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(18,8))\n",
    "    plt.plot(0,0, history.history['accuracy'], label='Accuracy', lw=3)\n",
    "    plt.plot(0,0, history.history['loss'], label='Loss', lw=3)\n",
    "    plt.plot(0,0, history.history['val_accuracy'], label='Val accuracy', lw=3, linestyle='--')\n",
    "    plt.legend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescaleFrame(frame, scale):\n",
    "    width = int(frame.shape[1] * scale)\n",
    "    height = int(frame.shape[1] * scale)\n",
    "    print(width, height)\n",
    "    dimensions = (width, height)\n",
    "    \n",
    "    return cv.resize(frame, dimensions, interpolation=cv.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom_at(img, zoom=1, angle=0, coord=None):\n",
    "    \n",
    "    cy, cx = [ i/2 for i in img.shape[:-1] ] if coord is None else coord[::-1]\n",
    "    \n",
    "    rot_mat = cv.getRotationMatrix2D((cx,cy), angle, zoom)\n",
    "    result = cv.warpAffine(img, rot_mat, img.shape[1::-1], flags=cv.INTER_LINEAR)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_zoom(window_name, height):\n",
    "    \n",
    "    _, _, _, thresh_window_h = cv.getWindowImageRect(window_name)\n",
    "    ratio = (thresh_window_h-height)/125\n",
    "    if ratio < 1:\n",
    "        ratio = 1\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_28(name, copy_from, gray_range):\n",
    "    _, window = cv.threshold(copy_from, gray_range[0], gray_range[1], cv.THRESH_BINARY)\n",
    "    window = cv.resize(name, (28,28), interpolation=cv.INTER_AREA)\n",
    "    window = window.astype(\"float32\") / 255.0\n",
    "    window = np.expand_dims(window, axis=-1)\n",
    "    return window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(window):\n",
    "    prediction = model.predict(window.reshape(1,28,28))\n",
    "    predargmax = np.argmax(prediction)\n",
    "    return predargmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_x(contours):\n",
    "    cent_moment = cv.moments(contours)\n",
    "    try:\n",
    "        answer = (int(cent_moment['m10']/cent_moment['m00']))\n",
    "        return answer\n",
    "    except ZeroDivisionError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_window(thresh, idx, cnt):\n",
    "        x,y,w,h = cv.boundingRect(cnt)\n",
    "        centercoords = [round(x+(w/2)), round(y+(h/2))]\n",
    "        gray_range = (150, 255)\n",
    "        fill_color = (0,0,0)\n",
    "        window_name = 'Win_Number: ' + str(idx)\n",
    "        _, _, window_w, window_h = cv.getWindowImageRect('Black & White (gray threshold)')\n",
    "    \n",
    "        # Filter out bounding boxed with a low height\n",
    "        if (h) > 100:\n",
    "            # Zoom onto number\n",
    "            zoom_ratio = calculate_zoom('Black & White (gray threshold)', h)\n",
    "            \n",
    "            # Create window\n",
    "            _, temp_window = cv.threshold(thresh, gray_range[0], gray_range[1], cv.THRESH_BINARY)\n",
    "            \n",
    "            border = 5\n",
    "            # Top\n",
    "            cv.rectangle(temp_window, (0, y-border), (window_w, 0), fill_color, -1)\n",
    "            # Bottom\n",
    "            cv.rectangle(temp_window, (0, y+h), (window_w, window_h), fill_color, -1)\n",
    "            # Left\n",
    "            cv.rectangle(temp_window, (x-border, 0), (0, window_h), fill_color, -1)\n",
    "            # Right\n",
    "            cv.rectangle(temp_window, (x+w+border, 0), (window_w, window_h), fill_color, -1)\n",
    "            temp_window = zoom_at(temp_window, zoom_ratio, 0, centercoords)\n",
    "            #cv.circle(temp_window, centercoords, 10, (255,255,255), 2)\n",
    "\n",
    "            #cv.putText(temp_window, 'Ratio: ' + str(zoom_ratio), (20,80), cv.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n",
    "            \n",
    "            # Convert window to 28x28 for prediction (data trained on 28x28)\n",
    "            temp_28 = convert_28(temp_window, thresh, gray_range)\n",
    "            # Predict\n",
    "            predargmax = predict(temp_28)\n",
    "            # Bounding Box\n",
    "            cv.rectangle(thresh, (x,y), (x+w, y+h), (255, 255, 0), 4)\n",
    "            \n",
    "            cv.putText(temp_window, 'Prediction: ' + str(predargmax), (20,40), cv.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "            cv.putText(temp_window, 'Prediction: ' + str(predargmax), (20,40), cv.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1)\n",
    "            \n",
    "            cv.imshow(window_name, temp_window)\n",
    "            cv.moveWindow(window_name, cv.getWindowImageRect('Gray scale')[2]*(idx), cv.getWindowImageRect('Gray scale')[3])\n",
    "            \n",
    "            return predargmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv.VideoCapture(0)\n",
    "scale = 0.35\n",
    "gray_range = (150, 255)\n",
    "predictions = []\n",
    "cleared = True\n",
    "while True:\n",
    "    isTrue, frame = capture.read()\n",
    "    frame_resized = rescaleFrame(frame, scale)\n",
    "\n",
    "    # Grayscaled\n",
    "    gray = cv.cvtColor(frame_resized, cv.COLOR_BGR2GRAY)\n",
    "    gray_28 = convert_28(gray, gray, gray_range)\n",
    "    predargmax_gray_28 = predict(gray_28)\n",
    "\n",
    "    # Black and white\n",
    "    ret, thresh = cv.threshold(gray, gray_range[0], gray_range[1], cv.THRESH_BINARY)\n",
    "    thresh_28 = convert_28(thresh, thresh, gray_range)\n",
    "    predargmax_thresh_28 = predict(thresh_28)\n",
    "      \n",
    "      \n",
    "    _, result = cv.threshold(gray, gray_range[0], gray_range[1], cv.THRESH_BINARY)\n",
    "    cv.rectangle(result, (0, 0), (500,500), (255,255,255), -1)\n",
    "    \n",
    "      \n",
    "    number_contours, _ = cv.findContours(cv.morphologyEx(thresh, cv.MORPH_OPEN, np.ones((2,2))), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "    if len(number_contours) > 0:\n",
    "        try:\n",
    "            sorted_contours = sorted(number_contours, key = contour_x, reverse = False)\n",
    "        except TypeError:\n",
    "            pass\n",
    "        for idx, cnt in enumerate(sorted_contours):\n",
    "            answer = create_window(thresh, idx, cnt)\n",
    "            if answer is not None:\n",
    "                predictions.append(answer)\n",
    "            cleared = False\n",
    "        for x in range(len(predictions)):\n",
    "            placement = 50\n",
    "            space = 50\n",
    "            cv.putText(result, str(predictions[x]), (placement+(space*x),200), cv.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 5)\n",
    "            if x < len(predictions)-1:\n",
    "                cv.putText(result, '+', (round(placement+(space*x)+(space/2)),200), cv.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 3)\n",
    "            if x == len(predictions)-1:\n",
    "                cv.putText(result, '=', (round(placement+(space*x)+(space/2)),200), cv.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 3)\n",
    "                cv.putText(result, str(sum(predictions)), (placement+(space*(x+1)),200), cv.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 5)\n",
    "        predictions = []\n",
    "    else:\n",
    "        if not cleared:\n",
    "            for x in range(100):\n",
    "                window_name = 'Win_Number: ' + str(x)\n",
    "                cv.destroyWindow(window_name)\n",
    "            cleared = True\n",
    "\n",
    "\n",
    "    cv.putText(gray, 'Gray: ' + str(predargmax_gray_28), (20,40), cv.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    cv.putText(gray, 'Gray: ' + str(predargmax_gray_28), (20,40), cv.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1)\n",
    "    cv.putText(gray, 'B&W: ' + str(predargmax_thresh_28), (20,80), cv.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    cv.putText(gray, 'B&W: ' + str(predargmax_thresh_28), (20,80), cv.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1)\n",
    "           \n",
    "    cv.imshow('Gray scale', gray)\n",
    "    \n",
    "    cv.imshow('Black & White (gray threshold)', thresh)\n",
    "    cv.moveWindow('Black & White (gray threshold)', cv.getWindowImageRect('Gray scale')[2], 0)\n",
    "\n",
    "    cv.imshow('Maffs', result)\n",
    "    cv.moveWindow('Maffs', cv.getWindowImageRect('Gray scale')[2]*2, 0)\n",
    "    \n",
    "\n",
    "    if cv.waitKey(20) & 0xFF==ord('q'):\n",
    "        break\n",
    "    \n",
    "capture.release()\n",
    "cv.waitKey(100)\n",
    "cv.destroyAllWindows()\n",
    "cv.waitKey(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
